{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:08.533507Z",
     "start_time": "2020-02-18T16:02:06.339762Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:08.547987Z",
     "start_time": "2020-02-18T16:02:08.537753Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalize(x, m, s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:08.557835Z",
     "start_time": "2020-02-18T16:02:08.551868Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:08.566290Z",
     "start_time": "2020-02-18T16:02:08.562052Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:08.575613Z",
     "start_time": "2020-02-18T16:02:08.570481Z"
    }
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.032244Z",
     "start_time": "2020-02-18T16:02:08.579760Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.042845Z",
     "start_time": "2020-02-18T16:02:10.037440Z"
    }
   },
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.056946Z",
     "start_time": "2020-02-18T16:02:10.047412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.068718Z",
     "start_time": "2020-02-18T16:02:10.060606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 8, 4, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.079461Z",
     "start_time": "2020-02-18T16:02:10.071737Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.092368Z",
     "start_time": "2020-02-18T16:02:10.083808Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.138716Z",
     "start_time": "2020-02-18T16:02:10.095999Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.149108Z",
     "start_time": "2020-02-18T16:02:10.142382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 10]), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.164582Z",
     "start_time": "2020-02-18T16:02:10.152634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3124, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.175008Z",
     "start_time": "2020-02-18T16:02:10.168086Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.190200Z",
     "start_time": "2020-02-18T16:02:10.178917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5767e-04,  7.8793e-02,  1.0344e-01,  1.4949e-01, -9.3376e-02,\n",
       "         -1.2136e-01,  2.7272e-02, -6.5561e-02, -3.4483e-02, -1.7114e-01],\n",
       "        grad_fn=<SelectBackward>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64                  # batch size\n",
    "\n",
    "xb = x_train[0:bs]     # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.197578Z",
     "start_time": "2020-02-18T16:02:10.193506Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:10.206030Z",
     "start_time": "2020-02-18T16:02:10.201017Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.757142Z",
     "start_time": "2020-02-18T16:02:10.209681Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.776607Z",
     "start_time": "2020-02-18T16:02:12.760688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1835, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.788953Z",
     "start_time": "2020-02-18T16:02:12.779896Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.809687Z",
     "start_time": "2020-02-18T16:02:12.803038Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.821078Z",
     "start_time": "2020-02-18T16:02:12.815075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.830043Z",
     "start_time": "2020-02-18T16:02:12.824155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.840112Z",
     "start_time": "2020-02-18T16:02:12.833037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:12.855799Z",
     "start_time": "2020-02-18T16:02:12.843544Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad() # reset gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.025215Z",
     "start_time": "2020-02-18T16:02:12.859149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1073, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the \\__setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.042239Z",
     "start_time": "2020-02-18T16:02:15.030742Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.056022Z",
     "start_time": "2020-02-18T16:02:15.045261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = DummyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.066810Z",
     "start_time": "2020-02-18T16:02:15.059522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in mdl.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.088961Z",
     "start_time": "2020-02-18T16:02:15.069739Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0121, -0.0328,  0.0066,  ..., -0.0167,  0.0272,  0.0116],\n",
       "         [ 0.0264, -0.0072, -0.0351,  ...,  0.0055,  0.0256, -0.0112],\n",
       "         [ 0.0021, -0.0086, -0.0204,  ..., -0.0140, -0.0111, -0.0353],\n",
       "         ...,\n",
       "         [ 0.0034,  0.0139, -0.0088,  ...,  0.0172, -0.0338,  0.0329],\n",
       "         [-0.0159, -0.0175, -0.0095,  ..., -0.0036, -0.0151,  0.0353],\n",
       "         [-0.0266, -0.0019,  0.0086,  ...,  0.0101, -0.0007, -0.0133]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.1837e-03, -3.4371e-02,  2.5044e-02, -2.4482e-02, -1.8414e-04,\n",
       "          2.9602e-02,  2.9271e-02, -3.1810e-02, -1.5888e-02, -1.0929e-02,\n",
       "         -3.0370e-02,  9.7187e-03,  2.8297e-02, -2.7684e-03, -7.5857e-03,\n",
       "          8.0842e-03,  8.6672e-03,  8.9793e-03, -3.4119e-02,  9.8683e-06,\n",
       "         -7.0275e-03,  7.1224e-03, -1.6031e-02,  1.6088e-02,  1.4987e-02,\n",
       "         -3.3688e-02, -1.8240e-02, -2.4479e-02, -1.2146e-02, -2.4582e-02,\n",
       "         -1.7174e-03,  2.0068e-02, -3.2901e-02, -2.6137e-02, -1.5242e-02,\n",
       "          2.7342e-02, -1.7578e-02,  7.2496e-03,  1.9316e-02, -1.0393e-02,\n",
       "          1.4945e-02, -1.1040e-02, -1.3202e-02,  2.2149e-02, -1.7637e-02,\n",
       "         -2.3177e-02,  1.6635e-02, -3.0959e-02,  1.1858e-02, -3.5685e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0952, -0.0018, -0.0134,  0.0913, -0.1129, -0.0340, -0.1221, -0.0818,\n",
       "          -0.1199,  0.1180, -0.0316, -0.0712,  0.1106, -0.0891,  0.0731, -0.0435,\n",
       "          -0.0684,  0.0446,  0.1049, -0.0799,  0.0295, -0.0897, -0.0499,  0.1033,\n",
       "          -0.0659, -0.0398, -0.0298,  0.0792,  0.0417,  0.1282, -0.0274,  0.0339,\n",
       "          -0.0151, -0.0376, -0.1266, -0.0544, -0.0108,  0.0283,  0.0820, -0.0352,\n",
       "          -0.0652,  0.1160,  0.0358, -0.0532,  0.0543, -0.1031, -0.0895, -0.0460,\n",
       "          -0.0665, -0.1314],\n",
       "         [-0.0940,  0.1019, -0.1126, -0.0316,  0.0341,  0.0952, -0.0333, -0.0916,\n",
       "          -0.1052,  0.1151,  0.0526, -0.0452,  0.1338, -0.0050,  0.0720,  0.0286,\n",
       "           0.0923, -0.0904,  0.0922, -0.1182, -0.0776, -0.0434,  0.0053,  0.0114,\n",
       "           0.0174,  0.0946,  0.0990,  0.0531, -0.1085, -0.0094, -0.1380, -0.1396,\n",
       "           0.0516,  0.0816,  0.0813,  0.0479,  0.0177, -0.0315,  0.0680, -0.1408,\n",
       "          -0.0686,  0.0305, -0.1230,  0.0904,  0.1111, -0.0833,  0.1292, -0.0571,\n",
       "           0.0461, -0.0991],\n",
       "         [ 0.0259,  0.1069, -0.1052,  0.0926, -0.0531,  0.0166, -0.0812,  0.1050,\n",
       "          -0.0442, -0.1024, -0.0526,  0.0299, -0.0515,  0.0389, -0.0919,  0.0306,\n",
       "           0.0625, -0.0087,  0.1187, -0.1383,  0.0131,  0.0029,  0.1353, -0.0252,\n",
       "          -0.0566,  0.0979,  0.1175,  0.0704,  0.1216,  0.1259,  0.0064, -0.0507,\n",
       "           0.0678,  0.0817, -0.1144, -0.0761,  0.0052, -0.0210, -0.0799,  0.0737,\n",
       "           0.0106,  0.0901,  0.1020, -0.0280, -0.1052,  0.1410, -0.0752,  0.0885,\n",
       "           0.0773,  0.0859],\n",
       "         [-0.0914,  0.0639, -0.1410,  0.0431,  0.0748, -0.0937, -0.0148,  0.1375,\n",
       "           0.0730,  0.0643,  0.1146, -0.0086,  0.0524,  0.0116, -0.0503, -0.0320,\n",
       "           0.0175,  0.1196, -0.0321, -0.0196,  0.0349, -0.1282, -0.1166,  0.0357,\n",
       "           0.0665, -0.0856,  0.0917,  0.1364,  0.1374, -0.0777, -0.0387, -0.0596,\n",
       "          -0.0013,  0.0965,  0.0323,  0.0114,  0.0261,  0.0083,  0.1299,  0.0098,\n",
       "          -0.0496, -0.1009,  0.0004,  0.0903,  0.0688, -0.1374, -0.0447, -0.1364,\n",
       "           0.0333, -0.0891],\n",
       "         [-0.1097, -0.0966,  0.0602, -0.1401,  0.1085, -0.0381, -0.1256, -0.0706,\n",
       "          -0.1168, -0.1205, -0.1099, -0.0273, -0.0637, -0.1335, -0.0421,  0.1377,\n",
       "          -0.1307,  0.0816,  0.1149, -0.1200,  0.0602, -0.0643, -0.0833,  0.0929,\n",
       "           0.0677,  0.1366,  0.0274, -0.1365,  0.0424, -0.1122,  0.0121,  0.1214,\n",
       "          -0.0141,  0.0142,  0.1278, -0.0499, -0.0467, -0.1236, -0.0711,  0.0489,\n",
       "          -0.0079,  0.1261, -0.0696,  0.0696, -0.0690, -0.0871, -0.1237,  0.0914,\n",
       "           0.0444,  0.0934],\n",
       "         [ 0.0413,  0.0116,  0.0969, -0.1158,  0.0584, -0.1229,  0.0295,  0.0641,\n",
       "          -0.1292, -0.0601,  0.0769,  0.0080,  0.1357,  0.0388, -0.0630,  0.0141,\n",
       "           0.1334,  0.1194, -0.1079,  0.0109,  0.1096, -0.0022, -0.0213, -0.0084,\n",
       "           0.1332, -0.1376, -0.0898, -0.0405,  0.1232,  0.1406,  0.0362,  0.0626,\n",
       "           0.1344, -0.0284, -0.0769,  0.0378,  0.0826, -0.0939,  0.1046, -0.0308,\n",
       "          -0.0420, -0.0276,  0.0436, -0.0416,  0.0334,  0.0204,  0.0769,  0.0099,\n",
       "          -0.0885, -0.0981],\n",
       "         [ 0.1349, -0.0524,  0.0507, -0.0801, -0.0754, -0.0540,  0.1361,  0.0707,\n",
       "          -0.1214, -0.0476,  0.1143,  0.0661, -0.0754, -0.0094, -0.1032, -0.0547,\n",
       "           0.1312,  0.0567,  0.0750,  0.0304,  0.1358, -0.0413, -0.0910, -0.0840,\n",
       "          -0.0312, -0.0651,  0.0944, -0.1091, -0.0121,  0.0037,  0.0741, -0.0707,\n",
       "           0.0404, -0.0193,  0.0405, -0.0265,  0.0217,  0.1086,  0.0275,  0.0237,\n",
       "          -0.0539, -0.1077, -0.1382,  0.0759, -0.0966,  0.0535, -0.0177,  0.0991,\n",
       "          -0.0550, -0.0718],\n",
       "         [-0.0891, -0.0495, -0.1294, -0.1180, -0.0538,  0.0777,  0.0408, -0.0806,\n",
       "          -0.1263, -0.1159, -0.0407, -0.1133, -0.1107, -0.1080,  0.1029,  0.0070,\n",
       "          -0.0344, -0.0998,  0.0389, -0.0076,  0.1146, -0.1183, -0.0817,  0.1379,\n",
       "           0.1007,  0.0921,  0.0145, -0.1387, -0.1256,  0.0146,  0.0820,  0.0231,\n",
       "           0.1310,  0.1173, -0.1323, -0.0334, -0.1097,  0.1065, -0.0053,  0.0644,\n",
       "           0.0151,  0.0030, -0.0441,  0.0291, -0.0708,  0.0550,  0.0915,  0.0850,\n",
       "          -0.0790,  0.0418],\n",
       "         [ 0.0799,  0.0134,  0.0925, -0.0051,  0.0424, -0.0261, -0.1236, -0.0790,\n",
       "           0.0499, -0.0520,  0.0940,  0.0561,  0.0548,  0.0446,  0.0009, -0.1334,\n",
       "           0.0389,  0.0626, -0.1059,  0.0390, -0.0470,  0.0151,  0.0736,  0.1342,\n",
       "          -0.0477, -0.0006, -0.0630,  0.0317, -0.0321, -0.0214,  0.0965,  0.0471,\n",
       "           0.1161,  0.1327, -0.0711, -0.1086, -0.0749,  0.0996, -0.0158,  0.0619,\n",
       "           0.0208, -0.0685, -0.0013,  0.1205, -0.1191, -0.0770, -0.0264,  0.0974,\n",
       "          -0.0075,  0.0439],\n",
       "         [-0.0398, -0.0038,  0.0585, -0.1063,  0.0611, -0.1386, -0.1110,  0.1164,\n",
       "          -0.1085,  0.0438,  0.1319,  0.0652,  0.0123, -0.1330, -0.0612,  0.1288,\n",
       "          -0.1147,  0.0291, -0.0529,  0.1247,  0.1276, -0.0356, -0.1253,  0.0859,\n",
       "           0.1405, -0.0529, -0.0768,  0.0745,  0.1150,  0.0645, -0.1061,  0.0900,\n",
       "          -0.0333, -0.0650,  0.1395,  0.0319, -0.0687,  0.0827,  0.1187, -0.0551,\n",
       "           0.0695,  0.0811, -0.0266,  0.0824,  0.0151, -0.0593, -0.0569, -0.0688,\n",
       "          -0.0206,  0.1102]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0276,  0.0996,  0.1231, -0.1255, -0.0343,  0.0718, -0.0575,  0.0920,\n",
       "          0.0718,  0.0838], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in mdl.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.097233Z",
     "start_time": "2020-02-18T16:02:15.091932Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can use the original layers approach, but we have to register the modules.\n",
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.107143Z",
     "start_time": "2020-02-18T16:02:15.100011Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.124935Z",
     "start_time": "2020-02-18T16:02:15.109864Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.135473Z",
     "start_time": "2020-02-18T16:02:15.128088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.143208Z",
     "start_time": "2020-02-18T16:02:15.138418Z"
    }
   },
   "outputs": [],
   "source": [
    "# nn.ModuleList dows the registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.154716Z",
     "start_time": "2020-02-18T16:02:15.146488Z"
    }
   },
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.162165Z",
     "start_time": "2020-02-18T16:02:15.157789Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SequentialModel(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:15.175602Z",
     "start_time": "2020-02-18T16:02:15.165231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:17.675857Z",
     "start_time": "2020-02-18T16:02:15.178451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2125, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.SequentialÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:17.686773Z",
     "start_time": "2020-02-18T16:02:17.679281Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.833178Z",
     "start_time": "2020-02-18T16:02:17.690264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0363, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.945938Z",
     "start_time": "2020-02-18T16:02:19.835852Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.Sequential??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.956088Z",
     "start_time": "2020-02-18T16:02:19.949428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's replace our previous manually coded optimization step:\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "and instead use just:\n",
    "\n",
    "opt.step()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.966441Z",
     "start_time": "2020-02-18T16:02:19.958847Z"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.975643Z",
     "start_time": "2020-02-18T16:02:19.969668Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:19.983395Z",
     "start_time": "2020-02-18T16:02:19.978514Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:21.948835Z",
     "start_time": "2020-02-18T16:02:19.986199Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:21.968611Z",
     "start_time": "2020-02-18T16:02:21.952119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1736, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:21.975947Z",
     "start_time": "2020-02-18T16:02:21.971806Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:22.006196Z",
     "start_time": "2020-02-18T16:02:21.979727Z"
    }
   },
   "outputs": [],
   "source": [
    "optim.SGD.step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:22.018833Z",
     "start_time": "2020-02-18T16:02:22.010072Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:22.031055Z",
     "start_time": "2020-02-18T16:02:22.021420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3282, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.433999Z",
     "start_time": "2020-02-18T16:02:22.034327Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.446421Z",
     "start_time": "2020-02-18T16:02:24.438261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0964, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.453768Z",
     "start_time": "2020-02-18T16:02:24.449560Z"
    }
   },
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "Instead, let's do these two steps together, by introducing a Dataset class:\n",
    "\n",
    "xb,yb = train_ds[i*bs : i*bs+bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.463881Z",
     "start_time": "2020-02-18T16:02:24.456458Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.472715Z",
     "start_time": "2020-02-18T16:02:24.466744Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.483706Z",
     "start_time": "2020-02-18T16:02:24.475200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:24.491349Z",
     "start_time": "2020-02-18T16:02:24.486523Z"
    }
   },
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:26.785755Z",
     "start_time": "2020-02-18T16:02:24.494189Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:26.801885Z",
     "start_time": "2020-02-18T16:02:26.789270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2542, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "\n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "    ...\n",
    "Let's make our loop much cleaner, using a data loader:\n",
    "\n",
    "for xb,yb in train_dl:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:26.812646Z",
     "start_time": "2020-02-18T16:02:26.805536Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:26.821184Z",
     "start_time": "2020-02-18T16:02:26.815810Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:26.829587Z",
     "start_time": "2020-02-18T16:02:26.824499Z"
    }
   },
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "assert xb.shape==(bs,28*28)\n",
    "assert yb.shape==(bs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:27.112194Z",
     "start_time": "2020-02-18T16:02:26.832804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:27.136284Z",
     "start_time": "2020-02-18T16:02:27.128915Z"
    }
   },
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:27.153205Z",
     "start_time": "2020-02-18T16:02:27.145166Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.307654Z",
     "start_time": "2020-02-18T16:02:27.156805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0414, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling\n",
    "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.322009Z",
     "start_time": "2020-02-18T16:02:29.311253Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.330367Z",
     "start_time": "2020-02-18T16:02:29.325590Z"
    }
   },
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.343359Z",
     "start_time": "2020-02-18T16:02:29.333923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,False)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.358013Z",
     "start_time": "2020-02-18T16:02:29.346285Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.369002Z",
     "start_time": "2020-02-18T16:02:29.360653Z"
    }
   },
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.377966Z",
     "start_time": "2020-02-18T16:02:29.372320Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:29.749371Z",
     "start_time": "2020-02-18T16:02:29.380615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:33.246631Z",
     "start_time": "2020-02-18T16:02:29.752583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1171, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:33.254839Z",
     "start_time": "2020-02-18T16:02:33.249884Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:33.265415Z",
     "start_time": "2020-02-18T16:02:33.258039Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collate_fn receives a list of tuples if your \\__getitem__ function from a Dataset subclass returns a tuple, or just a normal list if your Dataset subclass returns only one element. Its main objective is to create your batch without spending much time implementing it manually. Try to see it as a glue that you specify the way examples stick together in a batch. If you donât use it, PyTorch only put batch_size examples together as you would using torch.stack (not exactly it, but it is simple like that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:36.279780Z",
     "start_time": "2020-02-18T16:02:33.268116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1579, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:36.288084Z",
     "start_time": "2020-02-18T16:02:36.282726Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True) #drop_last drop the last incomplete mini-batch\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:39.180616Z",
     "start_time": "2020-02-18T16:02:36.291311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1021, grad_fn=<NllLossBackward>), tensor(0.9844))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:39.195614Z",
     "start_time": "2020-02-18T16:02:39.183826Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Handle batchnorm / dropout\n",
    "        model.train()\n",
    "#         print(model.training)\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         print(model.training)\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dls returns dataloaders for the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:39.205337Z",
     "start_time": "2020-02-18T16:02:39.197960Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:54.982620Z",
     "start_time": "2020-02-18T16:02:39.207689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2934) tensor(0.9159)\n",
      "1 tensor(0.1232) tensor(0.9643)\n",
      "2 tensor(0.5765) tensor(0.8702)\n",
      "3 tensor(0.1057) tensor(0.9698)\n",
      "4 tensor(0.2534) tensor(0.9296)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:54.989284Z",
     "start_time": "2020-02-18T16:02:54.985442Z"
    }
   },
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T16:02:55.269181Z",
     "start_time": "2020-02-18T16:02:54.993776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.1_minibatch_training.ipynb to ../src/nb_0.1.py\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ../src/notebook2script.py 0.1_minibatch_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
